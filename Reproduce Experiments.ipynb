{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy\n",
    "from scipy.stats import gamma, uniform\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import pickle as pkl\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sn\n",
    "from IPython.display import IFrame\n",
    "from IPython.core.display import Image, display\n",
    "from wand.image import Image as wimage\n",
    "%matplotlib inline\n",
    "\n",
    "from src.data_loader import mnist_data, get_data_loader\n",
    "from src.utils import *\n",
    "from src.trainer import Trainer\n",
    "from src.config import cfg_from_file, cfg_from_list, cfg_set_log_file\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams[\"font.family\"] = \"serif\"\n",
    "rcParams[\"font.sans-serif\"] = [\"Palatino\"]\n",
    "rcParams[\"font.size\"] = 20\n",
    "\n",
    "PLOT_COLOR = (0.04,.34,.57)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('data/')\n",
    "small_data = data_dir / 'mnist.t7'\n",
    "trans_data = data_dir / 'mnist_trans.t7'\n",
    "clut_data = data_dir / 'mnist_cluttered.t7'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_dir = Path('configs/')\n",
    "conf_unsup = cfg_from_file(conf_dir / 'small_unsupervised.yaml')\n",
    "conf_sup  = cfg_from_file(conf_dir / 'small_supervised.yaml' )\n",
    "conf_bin3 =  cfg_from_file(conf_dir / 'bin3.yaml')\n",
    "conf_bin6 =  cfg_from_file(conf_dir / 'bin6.yaml')\n",
    "conf_trans = cfg_from_file(conf_dir / 'trans.yaml')\n",
    "conf_clut = cfg_from_file(conf_dir / 'cluttered.yaml')\n",
    "\n",
    "plot_dir = Path('plots/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_loader = get_data_loader(\n",
    "    small_data,\n",
    "    conf_unsup.TRAIN.BATCH_SIZE,\n",
    "    conf_unsup.SEED,\n",
    "    conf_unsup.TRAIN.NUM,\n",
    "    conf_unsup.TRAIN.VAL_NUM,\n",
    "    conf_unsup.TRAIN.IS_TRAIN,\n",
    "    conf_unsup.TRAIN.NUM_WORKERS,\n",
    "    conf_unsup.GPU,\n",
    "    conf_unsup.TRAIN.FRAC_LABELS,\n",
    ")\n",
    "\n",
    "trans_loader = get_data_loader(\n",
    "    trans_data,\n",
    "    conf_trans.TRAIN.BATCH_SIZE,\n",
    "    conf_trans.SEED,\n",
    "    conf_trans.TRAIN.NUM,\n",
    "    conf_trans.TRAIN.VAL_NUM,\n",
    "    conf_trans.TRAIN.IS_TRAIN,\n",
    "    conf_trans.TRAIN.NUM_WORKERS,\n",
    "    conf_trans.GPU,\n",
    "    conf_trans.TRAIN.FRAC_LABELS,\n",
    "    data_size=70000,\n",
    ")\n",
    "\n",
    "clut_loader = get_data_loader(\n",
    "    clut_data,\n",
    "    conf_clut.TRAIN.BATCH_SIZE,\n",
    "    conf_clut.SEED,\n",
    "    conf_clut.TRAIN.NUM,\n",
    "    conf_clut.TRAIN.VAL_NUM,\n",
    "    conf_clut.TRAIN.IS_TRAIN,\n",
    "    conf_clut.TRAIN.NUM_WORKERS,\n",
    "    conf_clut.GPU,\n",
    "    conf_clut.TRAIN.FRAC_LABELS,\n",
    "    data_size=70000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsup_trainer = Trainer(small_loader, conf_unsup)\n",
    "sup_trainer = Trainer(small_loader, conf_sup)\n",
    "bin3_trainer = Trainer(small_loader, conf_bin3)\n",
    "bin6_trainer = Trainer(small_loader, conf_bin6)\n",
    "trans_trainer = Trainer(trans_loader, conf_trans)\n",
    "clut_trainer = Trainer(clut_loader, conf_clut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsup_trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# display(IFrame(plot_small / 'saccade_dist.pdf', width=600, height=300))\n",
    "# display(Image.open(plot_small / 'num4.png'))\n",
    "wimage(filename=plot_small / 'saccade_dist.pdf')\n",
    "# wimage(filename=plot_small / 'num4.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pixel Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 10000\n",
    "N = 100000\n",
    "data = mnist_data('../mnist_small.t7', torch.arange(N-num,N))\n",
    "scaler = StandardScaler()\n",
    "x_data = data.labeled\n",
    "x_norm = scaler.fit_transform(x_data.view(num,-1))\n",
    "y_data = data.labels.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=50. / num,\n",
    "                         multi_class='multinomial',\n",
    "                         penalty='l1', solver='saga', tol=0.1).fit(x_norm,y_data)\n",
    "clf.score(x_norm,y_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_norm = torch.tensor(x_norm).view(num,30,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 8\n",
    "off = size // 2\n",
    "pad_dims = (\n",
    "        off + 1,\n",
    "        off + 1,\n",
    "        off + 1,\n",
    "        off + 1,\n",
    "    )\n",
    "x_pad = F.pad(x_norm, pad_dims, \"constant\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = torch.zeros(30,30)\n",
    "for i in range(30):\n",
    "    for j in range(30):\n",
    "        \n",
    "        from_x, to_x = i+1,i+2*off+1\n",
    "        from_y, to_y = j+1,j+2*off+1\n",
    "        \n",
    "        d1 = torch.zeros_like(x_pad)\n",
    "        d1[:,from_y:to_y,from_x:to_x] = x_pad[:,from_y:to_y,from_x:to_x]\n",
    "        inp = d1[:,off+1:-(off+1),off+1:-(off+1)]\n",
    "\n",
    "        score = clf.score(inp.contiguous().view(num,-1),y_data)\n",
    "        scores[j,i] = score\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    for j in range(30):\n",
    "        \n",
    "        from_to_x = torch.arange(i-off,i+off) + off + 1\n",
    "        from_to_y = torch.arange(j-off,j+off) + off + 1\n",
    "    \n",
    "        d1 = d[:,from_to_y,from_to_x].view(num,-1)\n",
    "        loc[:,0] = (i / 30) * 2 - 1\n",
    "        loc[:,1] = (i / 30) * 2 - 1\n",
    "        features = torch.cat((d1,loc),-1)\n",
    "        score = clf.score(features,y)\n",
    "        scores[j,i] = score\n",
    "        p = sum(clf.predict(features))\n",
    "        if p:\n",
    "            print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dists = dists.flatten()\n",
    "\n",
    "x = np.linspace(0,30,100)\n",
    "param = gamma.fit(all_dists)\n",
    "pdf_fitted = gamma.pdf(x, *param)\n",
    "print(param)\n",
    "\n",
    "samples_gamma = gamma.rvs(*param,1000)\n",
    "samples_uniform = uniform.rvs(4,10,100)\n",
    "\n",
    "samples = np.concatenate([samples_gamma,samples_uniform])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.set(font=\"serif\",font_scale=2,context='paper', style='dark', rc={\"lines.linewidth\": 2.5})\n",
    "x = np.linspace(0,30,100)\n",
    "f = plt.figure(figsize=(12,9))\n",
    "plt.hist(all_dists,bins=range(30), ec='white', density=True, alpha=.6, label='Saccades')\n",
    "plt.plot(x,pdf_fitted,label='Gamma')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.xlabel('Amplitude')\n",
    "plt.legend()\n",
    "f.savefig('saccade_dist.pdf', bbox_inches = 'tight', pad_inches = 0, dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,30,30)\n",
    "f, ax1 = plt.subplots(1,1,figsize=(12,9))\n",
    "ax1.hist(all_dists,bins=x, color=sn.color_palette()[0],ec='white', density=True, alpha=.6, label='Predict')\n",
    "ax2 = ax1.twinx().twiny()\n",
    "x = np.linspace(0,60,30)\n",
    "ax2.hist(dists_search.flatten(),bins=x, color=sn.color_palette()[1],ec='white', density=True, alpha=.6, label='Search')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.xlabel('Amplitude')\n",
    "# ask matplotlib for the plotted objects and their labels\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2, labels + labels2, loc=0)\n",
    "#f.savefig('saccade_dist.pdf', bbox_inches = 'tight', pad_inches = 0, dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(12,9))\n",
    "for c,i in enumerate([0,4]):\n",
    "    plt.hist(dists[:,i],bins=range(30),ec='white',density=True, fill=True, alpha=.6, label=f'saccade {i+1}')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.xlabel('Amplitude')\n",
    "plt.legend()    \n",
    "f.savefig('amp_dist_first_last.pdf', bbox_inches = 'tight', pad_inches = 0, dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_max = var_dist.view(*var_dist.shape[:2],-1).max(-1)[0]\n",
    "var_max_search = var_search.view(*var_search.shape[:2],-1).max(-1)[0]\n",
    "var_sum = var_dist.view(*var_dist.shape[:2],-1).sum(-1)\n",
    "var_mean = var_dist.view(*var_dist.shape[:2],-1).mean(-1)\n",
    "print(var_dist.shape)\n",
    "print(var_max.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(12,9))\n",
    "for c,i in enumerate([0,4]):\n",
    "    plt.hist(var_max[:,i],bins=20,ec='white',density=True, fill=True, alpha=.8, label=f'saccade {i+1}')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.xlabel('Uncertainty')\n",
    "plt.xlim([0,0.22])\n",
    "plt.legend()    \n",
    "# f.savefig('var_dist_first_last.pdf', bbox_inches = 'tight', pad_inches = 0, dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "var_max_norm = (var_max/var_max.max()) * 1200\n",
    "\n",
    "f = plt.figure(figsize=(12,9))\n",
    "\n",
    "x = np.linspace(0,var_max_norm.max(),50)\n",
    "digitized = np.digitize(var_max_norm[:,:-1].flatten(), x) \n",
    "y_data = torch.tensor([dists.flatten()[digitized == i].mean() for i in range(len(x))])\n",
    "plt.scatter(x[:25],y_data[:25],label='saccades',s=50)\n",
    "plt.ylabel('Saccade Amplitude')\n",
    "plt.xlabel('Uncertainty')\n",
    "\n",
    "\n",
    "a = 120; b = 30;\n",
    "c = 18; d = 7.07;\n",
    "y_func = lambda x,a,b,c,d: b*np.exp(-a/(x))-((x-c)>0)*(b*np.exp(-a/(x-c))) + d\n",
    "# y_func = lambda x,a,b,c,d: b*np.exp(-a/(x+c))-(b*np.exp(-a/(x))) + d\n",
    "low = [0,0,0,0]\n",
    "high = 150\n",
    "popt, pcov = scipy.optimize.curve_fit(y_func,x,y_data.numpy()[:],p0=[a,b,c,d], bounds=(low,high))\n",
    "print(popt)\n",
    "\n",
    "a,b,c,d = popt\n",
    "plt.plot(x[:25],y_func(x,a,b,c,d)[:25],c=sn.color_palette()[1],label='fit')\n",
    "plt.legend()\n",
    "# f.savefig('amp_unc.pdf', bbox_inches = 'tight', pad_inches = 0, dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(12,9))\n",
    "for c,i in enumerate([4,0]):\n",
    "    plt.hist(var_max_search[:,i],bins=np.linspace(0,var_max_search[:,i].max(),30),ec='white',density=True, fill=True, alpha=.8, label=f'saccade {i+1}')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.xlabel('Uncertainty')\n",
    "plt.xlim([0,2e-3])\n",
    "plt.ylim([0,15000])\n",
    "plt.ticklabel_format(style='sci', axis='both',useOffset=False,scilimits=(-1,1))\n",
    "plt.legend()    \n",
    "f.savefig('var_dist_first_last_search.pdf', bbox_inches = 'tight', pad_inches = 0, dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_max_search_norm = (var_max_search/var_max_search.max()) * 1200\n",
    "\n",
    "f = plt.figure(figsize=(12,9))\n",
    "\n",
    "x = np.linspace(0,var_max_search_norm.max(),50)\n",
    "digitized = np.digitize(var_max_search_norm[:,:-1].flatten(), x) \n",
    "y_data = torch.tensor([dists.flatten()[digitized == i].mean() for i in range(len(x))])\n",
    "plt.scatter(x[:25],y_data[:25],label='saccades',s=50)\n",
    "plt.ylabel('Saccade Amplitude')\n",
    "plt.xlabel('Uncertainty')\n",
    "\n",
    "a = 120; b = 30;\n",
    "c = 18; d = 22.5;\n",
    "popt, pcov = scipy.optimize.curve_fit(y_func,x,y_data.numpy()[:],p0=[a,b,c,d], bounds=(low,high))\n",
    "print(popt)\n",
    "\n",
    "a,b,c,d = popt\n",
    "plt.plot(x[:25],y_func(x,a,b,c,d)[:25],c=sn.color_palette()[1],label='fit')\n",
    "plt.legend()\n",
    "# f.savefig('amp_unc_search.pdf', bbox_inches = 'tight', pad_inches = 0, dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difference Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_dist_class = pkl.load(open('class/var_dist.pkl','rb'))\n",
    "labels = pkl.load(open('class/labels.pkl','rb'))\n",
    "conf_matrix = pkl.load(open('class/conf_matrix.pkl','rb'))\n",
    "var_class_max = var_dist_class.view(*var_dist_class.shape[:2],-1).max(-1)[0]\n",
    "locs = pkl.load(open('no_class/locs.pkl','rb'))\n",
    "clocs = pkl.load(open('class/locs.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap(\"gist_heat\")\n",
    "f, ax = plt.subplots(3,1, figsize=(15,15))\n",
    "plt.rc('font', size=12)\n",
    "\n",
    "no_class = var_dist[:,:1,...].contiguous().view(-1,30,30).mean(0)\n",
    "no_class/=no_class.sum()\n",
    "ax[0].imshow(no_class, cmap=cmap)\n",
    "ax[0].axis('off')\n",
    "#ax[0].set_title('No Classification')\n",
    "\n",
    "classi = var_dist_class[:,:1,...].contiguous().view(-1,30,30).mean(0)\n",
    "classi/=classi.sum()\n",
    "ax[1].imshow(classi, cmap=cmap)\n",
    "ax[1].axis('off')\n",
    "#ax[1].set_title('Classification')\n",
    "\n",
    "im = ax[2].imshow(scores/scores.sum(), cmap=cmap)\n",
    "ax[2].axis('off')\n",
    "#ax[2].set_title('Logistic Regression')\n",
    "\n",
    "#mean_mean = x_data.squeeze().mean(0)#mean.squeeze().max(0)[0]\n",
    "#ax[3].imshow(mean_mean,cmap=cmap)\n",
    "# ax[3].axis('off')\n",
    "# ax[3].set_title('Mean digit')\n",
    "\n",
    "\n",
    "\n",
    "f.tight_layout()\n",
    "f.savefig('diff_class_log.pdf', bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap(\"gist_heat\")\n",
    "fig, ax = plt.subplots(3,2, figsize=(4,6))\n",
    "for idx,i in enumerate([3,6,9]):\n",
    "    c = var_dist[labels==i,4:-1,...].contiguous().view(-1,30,30).mean(0)\n",
    "    c/=c.max()\n",
    "    cc = var_dist_class[labels==i,4:-1,...].contiguous().view(-1,30,30).mean(0)\n",
    "    cc/=cc.max()\n",
    "    ax[idx,0].imshow(c, cmap=cmap)\n",
    "    ax[idx,0].axis('off')\n",
    "    ax[idx,1].imshow(cc, cmap=cmap)\n",
    "    ax[idx,1].axis('off')\n",
    "\n",
    "plt.subplots_adjust(wspace=.01, hspace=.1)\n",
    "#fig.tight_layout()\n",
    "fig.savefig('var_diff.pdf', bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 7))\n",
    "df_cm = pd.DataFrame(conf, range(conf.shape[0]), range(conf.shape[1]))\n",
    "sn.set(font_scale=1.1)  # for label size\n",
    "ax = sn.heatmap(\n",
    "    df_cm, annot=True, annot_kws={\"size\": 16}, cmap=\"OrRd\", fmt=\".2g\",vmin=0.8, vmax=1\n",
    ")  \n",
    "ax.set(xlabel=' ', ylabel=' ')\n",
    "fig.savefig('pred_corr.pdf', bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 7))\n",
    "df_cm = pd.DataFrame(cconf, range(conf.shape[0]), range(conf.shape[1]))\n",
    "sn.set(font_scale=1.1)  # for label size\n",
    "ax = sn.heatmap(\n",
    "    df_cm, annot=True, annot_kws={\"size\": 16}, cmap=\"OrRd\", fmt=\".2g\",vmin=0.8, vmax=1\n",
    ")  \n",
    "ax.set(xlabel=' ', ylabel=' ')\n",
    "fig.savefig('class_corr.pdf', bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 7))\n",
    "df_cm = pd.DataFrame(conf_matrix.numpy(), range(conf.shape[0]), range(conf.shape[1]))\n",
    "sn.set(font_scale=1.1)  # for label size\n",
    "ax = sn.heatmap(\n",
    "    df_cm, annot=True, annot_kws={\"size\": 16}, cmap=\"OrRd\", fmt=\"g\",vmin=0, vmax=20,cbar_kws={'format': '%.1f'}\n",
    ")  \n",
    "ax.set(xlabel='Predicted', ylabel='True')\n",
    "fig.savefig('conf_matrix.pdf', bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "f = plt.figure()\n",
    "plt.hist(var_max[:,i],bins=30, ec=plt.cm.Pastel1(0),density=True, fill=True,color=plt.cm.Pastel1(0), alpha=.6, label=f'var 0')\n",
    "plt.hist(var_class_max[:,i],bins=30, ec=plt.cm.Pastel1(1),density=True, fill=True,color=plt.cm.Pastel1(1), alpha=.6, label=f'var 1')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.xlabel('Amplitude')\n",
    "plt.legend()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_err = err_dist.view(10000,6,-1).mean(-1)\n",
    "mean_var = var_dist.view(10000,6,-1).mean(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(err_dist.flatten(),var_dist.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_value, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.set(font=\"serif\",font_scale=2,context='paper', style='dark', rc={\"lines.linewidth\": 2.5})\n",
    "errs = err_dist.view(10000,6,-1)  #/ 5\n",
    "vars = var_dist.view(10000,6,-1)\n",
    "\n",
    "y_err = errs.mean(-1).mean(0).numpy()\n",
    "y_var = vars.max(-1)[0].mean(0).numpy()\n",
    "f, ax = plt.subplots(2,1, sharex=True, figsize=(9,12))\n",
    "ax[0].plot(np.arange(6),y_err,marker='o',markersize=10)\n",
    "ax[0].set_ylim(0.,0.6)\n",
    "ax[0].set_ylabel('Prediction Error')\n",
    "ax[1].errorbar(np.arange(6),y_var,marker='o',markersize=10)\n",
    "ax[1].set_xlabel('Saccade number')\n",
    "ax[1].set_ylabel('Uncertainty')\n",
    "#ax[1].set_yticklabels(['  0','  1','  2','  3','  4','  5'])\n",
    "f.tight_layout()\n",
    "f.savefig('err_unc.pdf', bbox_inches = 'tight', pad_inches = 0, dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sn.set(font=\"serif\",font_scale=2,context='paper', style='dark', rc={\"lines.linewidth\": 2.5})\n",
    "errs = err_class.view(10000,6,-1)  #/ 5\n",
    "vars = var_class.view(10000,6,-1)\n",
    "\n",
    "y_err = errs.mean(-1).mean(0).numpy()\n",
    "y_var = vars.max(-1)[0].mean(0).numpy()\n",
    "f, ax = plt.subplots(1,2, figsize=(14,5))\n",
    "ax[0].plot(np.arange(6),y_err,marker='o',markersize=10)\n",
    "ax[0].set_ylim(0.,0.6)\n",
    "ax[0].set_xlabel('Saccade number')\n",
    "ax[0].set_ylabel('Prediction Error')\n",
    "ax[1].errorbar(np.arange(6),y_var,marker='o',markersize=10)\n",
    "ax[1].set_xlabel('Saccade number')\n",
    "ax[1].set_ylabel('Uncertainty')\n",
    "#ax[1].set_yticklabels(['  0','  1','  2','  3','  4','  5'])\n",
    "f.tight_layout()\n",
    "f.savefig('err_unc_class.pdf', bbox_inches = 'tight', pad_inches = 0, dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sn.set()\n",
    "fig, ax = plt.subplots(2, 5, subplot_kw=dict(projection='polar'), figsize=(15,7))\n",
    "fig.suptitle('Classification\\n')\n",
    "for i,ang in enumerate(angles):\n",
    "    if i < 5:\n",
    "        rose_plot(ax[0,i%5], ang, density=False, offset=0)\n",
    "        ax[0,i%5].set_title(f'{i}\\n')\n",
    "    else:\n",
    "        rose_plot(ax[1,i%5], ang, density=False, offset=0)\n",
    "        ax[1,i%5].set_title(f'{i}\\n')\n",
    "fig.tight_layout()    \n",
    "fig.savefig('roses_class.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
